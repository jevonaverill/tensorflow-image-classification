{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image Classification.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1TgHrWYTzvfCiKiJehbxDgAINvUisjLOB","authorship_tag":"ABX9TyOygRJJrWIRhLqtIpRb61U8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"l6pzPDDbEW_Y"},"source":["**Tensorflow 2.1**\n","\n","*   What is Image Classification?\n","*   What needs to be prepared to create an image classifier?\n","*   Prepare the dataset\n","*   Creating a pipeline for the input dataset\n","*   Building a Convolutional Neural Network Model\n","*   Using existing CNN Model Architecture\n","*   Compile the Model\n","*   Model Training\n","*   Model Save\n","*   Model Evaluation\n","*   Create Predict Function\n"]},{"cell_type":"markdown","metadata":{"id":"4oijHfVBGS4C"},"source":["# Mount Google Drive"]},{"cell_type":"code","metadata":{"id":"5o9aR-9d-EX0"},"source":["# mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JOueSLeW35EX"},"source":["# cd into TensorFlow directory in Google Drive\n","%cd '/content/gdrive/My Drive/TensorFlow/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LOsDPPXnGmkF"},"source":["# Preparing the Dataset\n","\n","In this process, we want to divide the data into 3 parts which are train, test, and validation, with proportions 80% of train data, 10% of test data, and 10% of validation data\n","\n","*   train (data for training)\n","*   validation (data for validating the training data)\n","*   test (data for testing the trained model)"]},{"cell_type":"code","metadata":{"id":"ktDZfSkELYCY"},"source":["# extract dataset if needed (in zip format)\n","# !unzip handphone-photos.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"27RZl-Cq9gQg"},"source":["import os\n","\n","mypath= 'handphone_photos/'\n","\n","file_name = []\n","tag = []\n","full_path = []\n","for path, subdirs, files in os.walk(mypath):\n","    for name in files:\n","        full_path.append(os.path.join(path, name)) \n","        tag.append(path.split('/')[-1])        \n","        file_name.append(name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S8iXjqnL9tKu"},"source":["import pandas as pd\n","\n","# input the variables that have been collected in the loop above into a dataframe to make the arrangement neatly\n","df = pd.DataFrame({\"path\":full_path,'file_name':file_name,\"tag\":tag})\n","df.groupby(['tag']).size()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pnyQIxA99uNV"},"source":["# check data sample\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PXi6h2LdAhRS"},"source":["# Train test split"]},{"cell_type":"code","metadata":{"id":"Bwm6C3Tg_3jw"},"source":["# load library for train test split\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3136-igi_9qL"},"source":["# used variables in data split\n","X= df['path']\n","y= df['tag']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iWVSNy_4MXHN"},"source":["# split first dataset become train and test data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=300)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CMNERw7tMaxZ"},"source":["# divide the test data into test and validation data\n","X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gh2TEpN-__Pf"},"source":["# combine into each dataframe\n","df_tr = pd.DataFrame({'path':X_train\n","              ,'tag':y_train\n","             ,'set':'train'})\n","\n","df_te = pd.DataFrame({'path':X_test\n","              ,'tag':y_test\n","             ,'set':'test'})\n","\n","df_val = pd.DataFrame({'path':X_val\n","              ,'tag':y_val\n","             ,'set':'validation'})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WLvN6JQRABhe"},"source":["print('train size', len(df_tr))\n","print('val size', len(df_te))\n","print('test size', len(df_val))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i-QQ5IbwADO3"},"source":["# view the proportion of each set whether it is okay or if there is something need to change\n","df_all = df_tr.append([df_te,df_val]).reset_index(drop=1)\\\n","\n","print('===================================================== \\n')\n","print(df_all.groupby(['set','tag']).size(),'\\n')\n","\n","print('===================================================== \\n')\n","\n","# check data sample\n","df_all.sample(3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GgVzM4AeAcCJ"},"source":["Tidy up to respective folders"]},{"cell_type":"code","metadata":{"id":"r1Ucr3MpAIUL"},"source":["# menghapus folder dataset jika diperlukan\n","#!rm -rf dataset/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"el2GDoAyAKf5"},"source":["import shutil\n","from tqdm.notebook import tqdm as tq"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3rEtsjDALmn"},"source":["datasource_path = \"handphone_photos/\"\n","dataset_path = \"dataset/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iVa4wO0aAN7x"},"source":["for index, row in tq(df_all.iterrows()):\n","    \n","    #detect filepath\n","    file_path = row['path']\n","    if os.path.exists(file_path) == False:\n","            file_path = os.path.join(datasource_path,row['tag'],row['image'].split('.')[0])            \n","    \n","    #make folder destination dirs\n","    if os.path.exists(os.path.join(dataset_path,row['set'],row['tag'])) == False:\n","        os.makedirs(os.path.join(dataset_path,row['set'],row['tag']))\n","    \n","    #define file dest\n","    destination_file_name = file_path.split('/')[-1]\n","    file_dest = os.path.join(dataset_path,row['set'],row['tag'],destination_file_name)\n","    \n","    #copy file from source to dest\n","    if os.path.exists(file_dest) == False:\n","        shutil.copy2(file_path,file_dest)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Liy0dP-8AqNL"},"source":["# Model Training\n","\n","Initialize global variables for model training\n","\n","In this section, we will determine how many epochs will be used for the training process, input dimension, batch_size, etc"]},{"cell_type":"code","metadata":{"id":"50M4yCqBAp35"},"source":["import tensorflow as tf\n","\n","# Input parameters for network\n","dim = (150, 150) # value will be different based on used network architecture\n","channel = (3, )\n","input_shape = dim + channel\n","\n","# Batch size\n","batch_size = 16\n","\n","# Epoch\n","epoch = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cFvPCVTDNcPJ"},"source":["The pipeline dataset is a command to extract data in the form of digital images from a folder into an array that can be read by tensorflow, the function used is \n","\n","```\n","# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","```\n","\n","This function is an Image data generator so that we generate image data from a file / folder that we created earlier. in this section we can determine what kind of generator / augmentation can be done.\n","For further reading please visit the following reference links:\n","- https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n","- https://keras.io/preprocessing/image/"]},{"cell_type":"code","metadata":{"id":"0opYqupXA-TL"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4kmiueLxNw3I"},"source":["# Data Augmentation\n","First, we define how the data transformation will be used\n","\n","This process will run:\n","* Rescaling data to 1/255\n","* 0.2 scale image shearing\n","* Zooming image with a range of 0.2\n","* and do a Horizontal flip\n","\n","Reference: https://towardsdatascience.com/machinex-image-data-augmentation-using-keras-b459ef87cd22"]},{"cell_type":"code","metadata":{"id":"969HV64pBCZ5"},"source":["train_datagen = ImageDataGenerator(rescale=1. / 255,\n","                                   shear_range=0.2,\n","                                   zoom_range=0.2,\n","                                   horizontal_flip=True)\n","\n","val_datagen = ImageDataGenerator(rescale=1. / 255,\n","                                 shear_range=0.2,\n","                                 zoom_range=0.2,\n","                                 horizontal_flip=True)\n","\n","test_datagen = ImageDataGenerator(rescale=1. / 255,\n","                                  shear_range=0.2,\n","                                  zoom_range=0.2,\n","                                  horizontal_flip=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zwRdg3cCN4GJ"},"source":["# Make the data flow\n","After defining the generator, then we define where the data source comes from. For example in this project we use data from a folder (dictionary) so that the code used is as follows:"]},{"cell_type":"code","metadata":{"id":"1LEgSsTTAunH"},"source":["# binary = [1,0,0,0,0] [0,1,0,0,0] [0,0,1,0,0] [0,0,0,1,0] [0,0,0,0,1]\n","# categorical = 1,2,3,4,5\n","\n","train_generator = train_datagen.flow_from_directory('dataset/train/',\n","                                                    target_size=dim,\n","                                                    batch_size=batch_size,\n","                                                    class_mode='categorical',\n","                                                    shuffle=True)\n","\n","val_generator = val_datagen.flow_from_directory('dataset/validation/',\n","                                                target_size=dim,\n","                                                batch_size=batch_size,\n","                                                class_mode='categorical',\n","                                                shuffle=True)\n","\n","test_generator = test_datagen.flow_from_directory('dataset/test/',\n","                                                  target_size=dim,\n","                                                  batch_size=batch_size,\n","                                                  class_mode='categorical',\n","                                                  shuffle=True)\n","\n","num_class = test_generator.num_classes\n","labels = train_generator.class_indices.keys()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vYGjL_IACdcj"},"source":["print(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a9CCzwUoCf8g"},"source":["def tf_data_generator(generator, input_shape):\n","    num_class = generator.num_classes\n","    tf_generator = tf.data.Dataset.from_generator(\n","        lambda: generator,\n","        output_types=(tf.float32, tf.float32),\n","        output_shapes=([None\n","                        , input_shape[0]\n","                        , input_shape[1]\n","                        , input_shape[2]]\n","                       ,[None, num_class])\n","    )\n","    return tf_generator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MMJp3IedCigG"},"source":["train_data = tf_data_generator(train_generator, input_shape)\n","test_data = tf_data_generator(test_generator, input_shape)\n","val_data = tf_data_generator(val_generator, input_shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pLb6MUs_CmJa"},"source":["#(Optional)Creating Convolutional Neural Network Structures\n","\n","We can skip this process if we want to use existing structures"]},{"cell_type":"code","metadata":{"id":"6SLWFiM3Cm_s"},"source":["from tensorflow.keras import layers, Sequential\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K-uk7QyoCpo9"},"source":["model = Sequential()\n","model.add(Conv2D(128, (3, 3), padding='same', input_shape=input_shape))\n","\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_class))\n","model.add(Activation('softmax'))\n","\n","# Compile the model\n","print('Compiling Model.......')\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"frgc1gs6CsQM"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YxHePJ-NC4fN"},"source":["# Using pre-build CNN structures (MobileNetV2)"]},{"cell_type":"code","metadata":{"id":"n_16ndg8C6OI"},"source":["from tensorflow.keras.applications import MobileNetV2\n","\n","# get base models\n","base_model = MobileNetV2(\n","    input_shape=input_shape,\n","    include_top=False,\n","    weights='imagenet',\n","    classes=num_class,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ImtAMM8C8L7"},"source":["from tensorflow.keras import layers,Sequential\n","from tensorflow.keras.models import Model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J93bLeshC8kZ"},"source":["# adding custom layers\n","x = base_model.output\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dropout(0.2)(x)\n","x = layers.Dense(1024, activation=\"relu\")(x)\n","\n","predictions = layers.Dense(num_class, activation=\"softmax\")(x)\n","model = Model(inputs=base_model.input, outputs=predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8WRn4nEKC-u7"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zuld0P9EDgQs"},"source":["# Compile the model\n","print('Compiling Model')\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tLIm3st6DiTs"},"source":["# Visualize the model\n","model_viz = tf.keras.utils.plot_model(model,\n","                          to_file='model.png',\n","                          show_shapes=True,\n","                          show_layer_names=True,\n","                          rankdir='TB',\n","                          expand_nested=True,\n","                          dpi=55)\n","model_viz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9SJQ2q1kxJYB"},"source":["# Using pre-build CNN structures (EfficientNet)"]},{"cell_type":"code","metadata":{"id":"ibFiOcnLLxMJ"},"source":["!pip install -U --pre efficientnet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zP0pm9FvL4Zz"},"source":["from efficientnet.tfkeras import EfficientNetB1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vO7-JDqlL5sO"},"source":["# get base models\n","base_model = EfficientNetB1(\n","    input_shape=input_shape,\n","    include_top=False,\n","    weights='noisy-student',\n","    classes=num_class,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NKc08ve3L_Zz"},"source":["from tensorflow.keras import layers,Sequential\n","from tensorflow.keras.models import Model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3qcfUrN1MBxY"},"source":["#Adding custom layers\n","x = base_model.output\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dropout(0.5)(x)\n","x = layers.Dense(1024, activation=\"relu\")(x)\n","\n","predictions = layers.Dense(num_class, activation=\"softmax\")(x)\n","model = Model(inputs=base_model.input, outputs=predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHcf08_XMDm8"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fwT7DpM8MMcX"},"source":["# Compile the model\n","print('Compiling Model.......')\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WJQyQhBqMO0K"},"source":["# Visualize the model\n","\n","model_viz = tf.keras.utils.plot_model(model,\n","                          to_file='model.png',\n","                          show_shapes=True,\n","                          show_layer_names=True,\n","                          rankdir='TB',\n","                          expand_nested=True,\n","                          dpi=55)\n","model_viz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XQsOD6LzDlMk"},"source":["# Model Training"]},{"cell_type":"code","metadata":{"id":"b7ryMx4WDm1a"},"source":["EPOCH = 10\n","\n","history = model.fit(x=train_data,\n","        steps_per_epoch=len(train_generator),\n","        epochs=EPOCH,\n","        validation_data=val_data,\n","        validation_steps=len(val_generator), \n","        shuffle=True,\n","        verbose = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qbd5r8skJoEQ"},"source":["history.history['loss']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4OlZzwnJqYX"},"source":["history.history['accuracy']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"swH1O1N3JsPR"},"source":["# Plot the training"]},{"cell_type":"code","metadata":{"id":"KxKRNtMrJtIH"},"source":["from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8eITEzVdJv9x"},"source":["# Plot history: MAE\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.ylabel('value')\n","plt.xlabel('No. epoch')\n","plt.legend(loc=\"upper left\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0qo7aQuKJyh1"},"source":["# Plot history: MSE\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.ylabel('value')\n","plt.xlabel('No. epoch')\n","plt.legend(loc=\"upper left\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X_uFlKHSJ2No"},"source":["#Save Model"]},{"cell_type":"code","metadata":{"id":"_Zx0uvN2J5LZ"},"source":["MODEL_BASE_PATH = \"model\"\n","PROJECT_NAME = \"medium_project\"\n","SAVE_MODEL_NAME = \"model-effinetb7-161120.h5\"\n","save_model_path = os.path.join(MODEL_BASE_PATH, PROJECT_NAME, SAVE_MODEL_NAME)\n","\n","if os.path.exists(os.path.join(MODEL_BASE_PATH, PROJECT_NAME)) == False:\n","    os.makedirs(os.path.join(MODEL_BASE_PATH, PROJECT_NAME))\n","    \n","print('Saving Model At {}...'.format(save_model_path))\n","model.save(save_model_path,include_optimizer=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p_n-JQ_VKE5g"},"source":["#Evaluate Model"]},{"cell_type":"code","metadata":{"id":"d0b64yESKFqV"},"source":["loss, acc = model.evaluate(test_data,steps=len(test_generator),verbose=0)\n","print('Accuracy on training data: {:.4f} \\nLoss on training data: {:.4f}'.format(acc,loss),'\\n')\n"," \n","loss, acc = model.evaluate(test_data,steps=len(test_generator),verbose=0)\n","print('Accuracy on test data: {:.4f} \\nLoss on test data: {:.4f}'.format(acc,loss),'\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KGSb__dkKNyB"},"source":["#Make a Prediction"]},{"cell_type":"code","metadata":{"id":"H904zIfmKOT5"},"source":["import requests\n","from io import BytesIO\n","from PIL import Image\n","import numpy as np\n","\n","# Parameters\n","input_size = (150,150) # customizable\n","\n","# Define Input Shape (3D)\n","channel = (3,)\n","input_shape = input_size + channel\n","\n","# Define Labels\n","labels = ['cropped', 'full']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uG6fEn0ZKT0Q"},"source":["def preprocess(img,input_size):\n","    nimg = img.convert('RGB').resize(input_size, resample= 0)\n","    img_arr = (np.array(nimg))/255\n","    return img_arr\n","    \n","def reshape(imgs_arr):\n","    return np.stack(imgs_arr, axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iyhp-HMfKVhK"},"source":["#cd into the TensorFlow directory in your Google Drive\n","%cd '/content/gdrive/My Drive/TensorFlow'\n","\n","# Load Model\n","from tensorflow.keras.models import load_model\n","MODEL_PATH = 'model/medium_project/model-effinetb7-161120.h5'\n","model = load_model(MODEL_PATH,compile=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"71WO_t8gKYZg"},"source":["#cd into the TensorFlow directory in your Google Drive\n","%cd '/content/gdrive/My Drive'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXpPrEVZZiFP"},"source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","img=['phone-pink.jpg', 'image.jpg', 'image-crop.jpg', 'testing-real (12).jpeg']\n","\n","for image_path in img:\n","  print(image_path)\n","  # read image\n","  im = Image.open(image_path)\n","  X = preprocess(im,input_size)\n","  X = reshape([X])\n","  y = model.predict(X)\n","\n","  plt.imshow(im)\n","  plt.show()\n","\n","  print( labels[np.argmax(y)], np.max(y) )"],"execution_count":null,"outputs":[]}]}